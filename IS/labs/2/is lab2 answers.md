1. Алфавит источника сообщения - это набор символов, которые используются для кодирования информации. Это может быть алфавит естественного языка (например, русский, английский), алфавит чисел и т.д.
2. Мощность алфавита источника сообщения - это количество символов, содержащихся в алфавите
3. Мощность алфавита белорусского языка 32 буквы.
4. Мощность алфавита русского языка 33 буквы.
5. Мощность алфавита «компьютерного» языка зависит от конкретного языка. Например, в бинарном коде мощность алфавита равна 2 (символы 0 и 1). В ASCII-кодировке мощность алфавита равна 128, поскольку она включает 128 уникальных символов.
6. Энтропия алфавита - это мера неопределённости или непредсказуемости появления какого-либо символа в алфавите. Она выражает степень хаотичности информации и количественно равна количеству информации на символ передаваемого сообщения.
7. Энтропия сообщения - это среднее количество информации на символ передаваемого сообщения. Это мера неопределённости или непредсказуемости появления какого-либо символа в сообщении.
8. Энтропия алфавита зависит от вероятностей появления различных символов в сообщениях, которые генерируются источником. Если алфавит состоит из меньшего количества символов, то энтропия будет ниже, так как возможные комбинации будут ограничены.
9. Шеннона H=−i=1∑n​pi​log2​pi​, Хартли H=log2​n
10. Для вычисления энтропии алфавита необходимо знать вероятности появления каждого символа в сообщениях. Это можно определить на основе статистического анализа большого количества сообщений от данного источника. 
11. Принципиальное различие между этими характеристиками заключается в том, что энтропия Шеннона учитывает вероятности появления символов, в то время как энтропия Хартли предполагает, что все символы равновероятны. Физический смысл энтропии заключается в измерении степени неопределенности или непредсказуемости информации. 
12. логарифм вероятности по основанию 2 отрицательный, потому что вероятность <= 1
13. Избыточность алфавита и избыточность сообщений относятся к наличию «лишних» символов или информации, которые не добавляют новой информации к сообщению. Это может проявляться в повторяющихся символах, стандартных фразах или шаблонах, которые можно предсказать. Принцип действия многих систем, включая системы сжатия данных и коррекции ошибок, основан на использовании этой избыточности.
14. бинарный (1), английский (4.7), белорусский (5), русский (5.044), если считать по Хартли
15. 5 (5.044)
16. xd
    - 0.25/0.75=0.811
    - 0/1=0
    - 0.5/0.5=1
17. kek
    - 1=0
    - 2=1
    - 8=3